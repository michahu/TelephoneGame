---
title: "Chain analytics"
output: html_notebook
---

# Imports

Import dependencies

```{r}
library(tidyverse)
library(tidyboot)
library(here)
library(viridis)
library(ggthemes)
```

# Squeeze plot (to check convergence)

```{r}
d.chains <- read_csv(here('./data/FrozenBertDataNew/BehavData/10_2000/21TokenSents/bert_new_gibbs_random_input_1.csv')) %>%
  bind_rows(read_csv(here('./data/FrozenBertDataNew/BehavData/10_2000/21TokenSents/bert_new_gibbs_random_input_new_1.csv'))) %>%
  filter(step == 0) %>%
  group_by(initial_sentence) %>%
  mutate(prob_class = ifelse(sentence_num > 4, 'high', 'low')) %>%
  filter(iter_num < 400) %>%
  filter(iter_num %in% seq(0,400,20))

d.chains %>%
  group_by(prob_class, iter_num) %>%
  tidyboot_mean(prob, nboot = 1000) %>%
  ggplot(aes(x = iter_num, y = empirical_stat, color = prob_class)) +
    geom_point(size = 3) +
    geom_line(size = 1) +
    geom_errorbar(aes(ymin =ci_lower, ymax = ci_upper), size = 1, width = 0) +
    stat_smooth(aes(y = prob, group = interaction(chain_num, sentence_num)), 
                data = d.chains, geom="line", alpha=0.1, size=1, span=.5) +
    theme_few() +
    ylim(-70, 0) +
    theme(aspect.ratio = 1, legend.position = 'none') +
    labs(y = 'sentence score',
         x = 'epoch')

ggsave('squeeze.pdf', width = 3, height = 3, units = 'in')
```

# Auto-correlation plot (to check auto-correlation)

```{r}
d.chains <- read_csv(here('data/FrozenBertDataNew/StatData/5_51000/11TokenSents/bert_new_gibbs_mixture_random_0.001_mask_init_input_1.csv')) %>%
  mutate(algorithm = 'gibbs_mixture') %>%
  bind_rows(read_csv(here('data/FrozenBertDataNew/StatData/5_51000/11TokenSents/bert_new_mh_mixture_1_random_sweep_0.001_mask_init_input_1.csv')) %>% 
              mutate(algorithm = 'mh_mixture')) %>%
  bind_rows(read_csv(here('data/FrozenBertDataNew/StatData/5_51000/11TokenSents/bert_new_gibbs_random_mask_init_input_1.csv')) %>% 
              mutate(algorithm = 'gibbs')) %>%
  filter(step==8) %>%
  filter(iter_num%%10==0)
```

## Read in chain 

We compute autocorrelation between sentence probabilities at different lags.

```{r}
d.lags <- d.chains %>%
  group_by(sentence_num, chain_num, algorithm) %>%
  mutate(`prevProb_1` = lag(prob),
         `prevProb_2` = lag(prob, 2),
         `prevProb_5` = lag(prob, 5),
         `prevProb_10` = lag(prob, 10),
         `prevProb_20` = lag(prob, 20),
         `prevProb_50` = lag(prob, 50),
         `prevProb_100` = lag(prob, 100),
         `prevProb_200` = lag(prob, 200),
         `prevProb_500` = lag(prob, 500),
         `prevProb_1000` = lag(prob, 1000)) %>%
  pivot_longer(starts_with('prevProb'), 
               values_to = 'prevProb', 
               names_to = 'lag') %>%
  filter(!is.na(prevProb)) %>%
  separate(lag, into = c('garbage', 'lag')) %>%
  mutate(lag = as.integer(lag)) %>%
  select(-garbage) %>%
  arrange(sentence_num, chain_num)
```

## Make plot

```{r}
d.cors <- d.lags %>%
  group_by(sentence_num, chain_num, algorithm, lag) %>%
  summarize(correlation = cor(prob, prevProb)) %>%
  group_by(algorithm, lag) %>%
  tidyboot_mean(correlation) %>%
  mutate(algorithm = case_when(algorithm == 'gibbs_mixture' ~ 'GSN mixture', 
                               algorithm == 'mh_mixture' ~ 'MH mixture',
                               TRUE ~ 'no mixture'))
```

```{r}
ggplot(d.cors, aes(x = lag*10, y = empirical_stat, linetype = algorithm)) +
    geom_point(data = d.cors %>% filter(lag %in% c(1)), size = 2.5) +
    geom_text(aes(label = algorithm), nudge_y = 0.03, hjust = 0, data = d.cors %>% filter(lag %in% c(100), algorithm == 'no mixture')) +
    geom_text(aes(label = algorithm), nudge_y = 0.03, hjust = 0, data = d.cors %>% filter(lag %in% c(100), algorithm == 'MH mixture')) +
    geom_text(aes(label = algorithm), nudge_y = -0.05, hjust = 0, data = d.cors %>% filter(lag %in% c(100), algorithm == 'GSN mixture')) +
    geom_line() +
    geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper),  alpha = 0.1, color = NA) +
    labs(y = 'auto-correlation', x = 'lag (epochs)') +
    theme_few() +
    xlim(NA, 5000) +
    theme(aspect.ratio = 1, legend.position = 'none')

ggsave('autocorrelation.pdf', width = 3, height = 3, units = 'in')
```

## Visualize edit rates 

```{r}
d.chains %>%
  filter(iter_num %% 100 == 0) %>%
  ggplot(aes(x = iter_num, y = edit_rate, color = algorithm, group = interaction(sentence_num, chain_num))) +
    geom_jitter(alpha = 0.05, size = 0.5, height = .05) +
    geom_smooth(method = 'loess', se=F, span = .5) +
    facet_wrap(~ algorithm) +
    theme_few() +
    theme(legend.position = 'none') +
    labs(y = 'edit rate', x = 'step')

ggsave('edit_rates.pdf', width = 6, height = 3, units = 'in')
```

```{r}
d.chains %>%
  filter(iter_num %% 100 == 0) %>%
  ggplot(aes(x = iter_num, y = accept_rate, color = algorithm, group = interaction(sentence_num, chain_num))) +
    geom_jitter(alpha = 0.05, size = 0.5, height = .05) +
    geom_smooth(method = 'loess', se=F, span = .5) +
    facet_wrap(~ algorithm) +
    theme_few() +
    theme(legend.position = 'none') +
    labs(y = 'accept rate', x = 'step')

ggsave('accept_rates.pdf', width = 6, height = 3, units = 'in')
```

## Visualize chains (Fig. 1)

Assumes we already have the tsne features `tsne_out.csv` written to file, from running `./movies/visualize_tsne.py`.

```{r}
library(ggnewscale)
tsne <- read_csv('./tsne_out.csv') %>%
  filter(edit_rate > 0) %>%
  mutate(step = substep + (max(substep) + 1) * iter_num) %>%
  select(sentence, sentence_num, step, x_tsne, y_tsne) %>%
  group_by(sentence_num) %>%
  mutate(prev_x = lag(x_tsne) ,
         prev_y = lag(y_tsne)) %>%
  filter(step < 16000)

tsne %>%
  ggplot(aes(x = x_tsne, y = y_tsne, color = step)) +
    geom_point(size = 10, color = 'grey', data = tsne %>% filter(step == 1)) +
    scale_color_gradient(low = 'red', high=  'black')+
    geom_point(size = .5, data = tsne %>% filter(sentence_num == 2)) +
    geom_segment(aes(xend = prev_x, yend = prev_y), 
                 arrow.fill = NULL, data = tsne %>% filter(sentence_num == 2)) +

    new_scale_color() +
    scale_color_gradient(low = 'blue', high=  'black')+
    geom_point(size = .5, aes(color = step), data = tsne %>% filter(sentence_num == 6)) +
    geom_segment(aes(xend = prev_x, yend = prev_y, color = step), 
                 arrow.fill = NULL, data = tsne %>% filter(sentence_num == 6)) +

      # uncomment this line to see text labels
    #geom_text(aes(label=sentence), size = 1)+
    scale_shape_manual(values = c(21)) +
    scale_alpha_continuous(range = c(0.5, 1))+
    theme_few(20) +
    theme(axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        legend.position = 'none') +
    labs(x = "", y = "") +
    guides(color = F, shape = F, alpha = F) +
    theme(aspect.ratio = 1)  #+

ggsave(filename = 'tsne.pdf',
       width = 5, height = 5)

```

## make a tsne animation

```{r}
out <- tsne %>%
  ggplot(aes(x = x_tsne, y = y_tsne, color = step)) +
    geom_point() +
    geom_segment(aes(xend = prev_x, yend = prev_y), arrow.fill = NULL) +
    theme_few(12) +
    scale_shape_manual(values = c(21)) +
    scale_alpha_continuous(range = c(0.5, 1))+
    scale_color_gradientn(colours = viridis(5))+
    guides(color = F, shape = F, alpha = F) +
    theme(aspect.ratio = 1)  +
    labs(title = '{tsne %>% filter(step == closest_state) %>% pull(sentence)}', x = "", y = "") +
    theme(axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank()) +
    #transition_time(step) +
    transition_states(step, transition_length = 0, state_length = .1) +
    shadow_mark() 

a <- animate(out, nframes = 1000, renderer = av_renderer('tsne.mp4'))
anim_save(filename = "tsne-animation.mp4")
```

